# This file is part of the Reproducible and Reusable Data Analysis Workflow
# Server (flowServ).
#
# Copyright (C) 2019-2021 NYU.
#
# flowServ is free software; you can redistribute it and/or modify it under the
# terms of the MIT License; see LICENSE file for more details.

"""Implementation of a workflow controller for serial workflows that uses the
local Docker daemon to execute workflow steps.
"""

from typing import Dict, List, Optional

import logging
import os

from flowserv.controller.serial.engine import SerialWorkflowEngine
from flowserv.controller.serial.result import ExecResult
from flowserv.service.api import APIFactory

import flowserv.model.workflow.state as serialize
import flowserv.util as util


class DockerWorkflowEngine(SerialWorkflowEngine):
    """The docker workflow engine is used to execute workflow templates for a
    given set of arguments using docker containers.

    the engine extends the multi-process controller for asynchronous execution.
    Workflow runs are executed by the docker_run() function.
    """
    def __init__(self, service: Optional[APIFactory] = None):
        """Initialize the super class using the docker_run execution function.

        Parameters
        ----------
        service: flowserv.service.api.APIFactory, default=None
            API factory for service callbach during asynchronous workflow
            execution.
        """
        super(DockerWorkflowEngine, self).__init__(
            service=service,
            exec_func=docker_run
        )


# -- Workflow execution function ----------------------------------------------


def exec_step(
    image: str, commands: List[str], rundir: str, env: Optional[Dict] = None
) -> ExecResult:
    """Execute a list of commands from a workflow steps synchronously using the
    Docker engine.

    Stops execution if one of the commands fails. Returns the combined result
    of all executed commands.

    Parameters
    ----------
    image: str
        Container image identifier.
    commands: list of string
        List of commands that are being executed.
    rundir: string
        Path to the working directory of the workflow run that this step
        belongs to.
    env: dict, default=None
        Mapping of environment variables that is passed to the subprocess run
        method.

    Returns
    -------
    (string, string, dict)
    """
    # Keep output to STDOUT and STDERR for all executed commands in the
    # respective attributes of the returned execution result.
    result = ExecResult()
    # Setup the workflow environment by obtaining volume information for all
    # directories in the run folder.
    volumes = dict()
    for filename in os.listdir(rundir):
        abs_file = os.path.abspath(os.path.join(rundir, filename))
        if os.path.isdir(abs_file):
            volumes[abs_file] = {'bind': '/{}'.format(filename), 'mode': 'rw'}
    # Run the individual commands using the local Docker deamon. Import
    # docker package here to avoid errors for installations that do not intend
    # to use Docker and therefore did not install the package.
    import docker
    from docker.errors import ContainerError, ImageNotFound, APIError
    client = docker.from_env()
    try:
        for cmd in commands:
            logging.info('{}'.format(cmd))
            logs = client.containers.run(
                image=image,
                command=cmd,
                volumes=volumes,
                auto_remove=True,
                environment=env,
                stdout=True
            )
            if logs:
                result.stdout.append(logs.decode('utf-8'))
    except (ContainerError, ImageNotFound, APIError) as ex:
        logging.error(ex)
        strace = '\n'.join(util.stacktrace(ex))
        logging.debug(strace)
        result.stderr.append(strace)
        result.exception = ex
        result.returncode = 1
    return result


def docker_run(run_id, rundir, state, output_files, steps):
    """Execute a list of workflow steps synchronously using the Docker engine.

    Returns a tuple containing the run identifier, the folder with the run
    files, and a serialization of the workflow state.

    Parameters
    ----------
    run_id: string
        Unique run identifier
    rundir: string
        Path to the working directory of the workflow run
    state: flowserv.model.workflow.state.WorkflowState
        Current workflow state (to access the timestamps)
    output_files: list(string)
        Relative path of output files that are generated by the workflow run
    steps: list(flowserv.model.workflow.serial.Step)
        List of expanded workflow steps from a template workflow specification

    Returns
    -------
    (string, string, dict)
    """
    logging.debug('start docker run {}'.format(run_id))
    for step in steps:
        for cmd in step.commands:
            exec_step(image=step.env, command=cmd, rundir=rundir)
    # Create list of output files that were generated.
    files = list()
    for relative_path in output_files:
        if os.path.exists(os.path.join(rundir, relative_path)):
            files.append(relative_path)
    # Workflow executed successfully
    result_state = state.success(files=files)
    logging.debug('finished run {} = {}'.format(run_id, result_state.type_id))
    return run_id, rundir, serialize.serialize_state(result_state)
