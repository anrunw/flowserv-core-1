# This file is part of the Reproducible and Reusable Data Analysis Workflow
# Server (flowServ).
#
# Copyright (C) [2019-2020] NYU.
#
# flowServ is free software; you can redistribute it and/or modify it under the
# terms of the MIT License; see LICENSE file for more details.

"""Implementation of a workflow controller for serial workflows that uses the
local Docker daemon to execute workflow steps.
"""

import docker
import os

from docker.errors import ContainerError, ImageNotFound, APIError

from flowserv.controller.multiproc import MultiProcessWorkflowEngine
from flowserv.model.workflow.resource import FSObject

import flowserv.controller.sync as sync
import flowserv.core.util as util


class DockerWorkflowEngine(MultiProcessWorkflowEngine):
    """The docker workflow engine is used to execute workflow templates for a
    given set of arguments using docker containers.

    the engine extends the multi-process controller for asynchronous execution.
    Workflow runs are executed by the docker_run() function.
    """
    def __init__(self, basedir=None):
        """Initialize the base directory under which all workflow runs are
        maintained. If the directory does not exist it will be created.

        Parameters
        ----------
        basedir: string
            Path to directory on disk
        """
        super(DockerWorkflowEngine, self).__init__(
            basedir=basedir,
            exec_func=docker_run
        )


# -- Workflow execution function -----------------------------------------------


def docker_run(run_id, rundir, state, output_files, steps, verbose):
    """Execute a list of workflow steps synchronously using the Docker engine.

    Returns a tuple containing the task identifier and a serialization of the
    workflow state.

    Parameters
    ----------
    run_id: string
        Unique run identifier
    rundir: string
        Path to the working directory of the workflow run
    state: flowserv.model.workflow.state.WorkflowState
        Current workflow state (to access the timestamps)
    output_files: list(string)
        Relative path of output files that are generated by the workflow run
    steps: list(flowserv.model.template.step.Step)
        List of expanded workflow steps from a template workflow specification
    verbose: bool, optional
        Output executed command statements if flag is True

    Returns
    -------
    (string, dict)
    """
    # Setup the workflow environment by obtaining volume information for all
    # directories in the run folder.
    volumes = dict()
    for filename in os.listdir(rundir):
        abs_file = os.path.abspath(os.path.join(rundir, filename))
        if os.path.isdir(abs_file):
            volumes[abs_file] = {'bind': '/{}'.format(filename), 'mode': 'rw'}
    # Run the individual workflow steps using the local Docker deamon.
    client = docker.from_env()
    try:
        for step in steps:
            for cmd in step.commands:
                client.containers.run(
                    image=step.env,
                    command=cmd,
                    volumes=volumes
                )
    except (ContainerError, ImageNotFound, APIError) as ex:
        return run_id, sync.serialize_state(state.error(messages=[str(ex)]))
    # Create dictionary of output files
    files = dict()
    for resource_name in output_files:
        files[resource_name] = FSObject(
            resource_id=util.get_unique_identifier(),
            resource_name=resource_name,
            file_path=os.path.join(rundir, resource_name)
        )
    # Workflow executed successfully
    return run_id, sync.serialize_state(state.success(resources=files))
