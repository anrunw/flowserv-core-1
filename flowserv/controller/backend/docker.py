# This file is part of the Reproducible Open Benchmarks for Data Analysis
# Platform (ROB).
#
# Copyright (C) 2019 NYU.
#
# ROB is free software; you can redistribute it and/or modify it under the
# terms of the MIT License; see LICENSE file for more details.

"""

"""

import docker
import os

from docker.errors import ContainerError, ImageNotFound, APIError

from flowserv.controller.backend.multiproc import MultiProcessWorkflowEngine
from flowserv.model.workflow.resource import FSObject

import flowserv.controller.backend.sync as sync
import flowserv.core.util as util


class DockerWorkflowEngine(MultiProcessWorkflowEngine):
    """The docker workflow engine is used to execute workflow templates for a
    given set of arguments using docker containers.

    the engine extends the multi-process controller for asynchronous execution.
    Workflow runs are executed by the docker_run() function.
    """
    def __init__(self, basedir=None):
        """Initialize the base directory under which all workflow runs are
        maintained. If the directory does not exist it will be created.

        Parameters
        ----------
        basedir: string
            Path to directory on disk
        """
        super(DockerWorkflowEngine, self).__init__(
            basedir=basedir,
            exec_func=docker_run
        )


# -- Workflow execution function -----------------------------------------------

def docker_run(run_id, run_dir, state, input_files, output_files, steps, verbose):
    """Execute a list of workflow steps synchronously using the Docker engine.

    Returns a tuple containing the task identifier and a serialization of the
    workflow state.

    Parameters
    ----------
    run_id: string
        Unique run identifier
    run_dir: string
        Path to the working directory of the workflow run
    state: flowserv.model.workflow.state.WorkflowState
        Current workflow state (to access the timestamps)
    input_files: list((string, string))
        List of source,target path pairs for files that are being copied
    output_files: list(string)
        Relative path of output files that are generated by the workflow run
    steps: list(flowserv.model.template.step.Step)
        List of expanded workflow steps from a template workflow specification
    verbose: bool, optional
        Output executed command statements if flag is True

    Returns
    -------
    (string, dict)
    """
    # Setup the workflow environment by copying input files and creating the
    # output directpries
    try:
        util.copy_files(files=input_files, target_dir=run_dir)
        # Create top-level folder for all expected result files (if it does not
        # exist already)
        for filename in output_files:
            dirname = os.path.dirname(filename)
            if dirname:
                # Create the directory if it does not exist
                out_dir = os.path.join(run_dir, dirname)
                if not os.path.isdir(out_dir):
                    os.makedirs(out_dir)
        # Create volume information for all directories in the run folder.
        volumes = dict()
        for filename in os.listdir(run_dir):
            abs_file = os.path.abspath(os.path.join(run_dir, filename))
            if os.path.isdir(abs_file):
                volumes[abs_file] = {'bind': '/{}'.format(filename), 'mode': 'rw'}
    except (OSError, IOError) as ex:
        return run_id, sync.serialize_state(state.error(messages=[str(ex)]))
    # Run the individual workflow steps using the local Docker deamon.
    client = docker.from_env()
    try:
        for step in steps:
            for cmd in step.commands:
                client.containers.run(
                    image=step.env,
                    command=cmd,
                    volumes=volumes
                )
    except (ContainerError, ImageNotFound, APIError) as ex:
        return run_id, sync.serialize_state(state.error(messages=[str(ex)]))
    # Create dictionary of output files
    files = dict()
    for resource_name in output_files:
        files[resource_name] = FSObject(
            resource_id=util.get_unique_identifier(),
            resource_name=resource_name,
            file_path=os.path.join(run_dir, resource_name)
        )
    return run_id, sync.serialize_state(state.success(resources=files))
